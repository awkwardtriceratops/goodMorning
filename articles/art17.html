<html><head><link rel="stylesheet" type="text/css" href="css.css"></head><h1 id="artitle">‘But I Saw It on Facebook’: Hoaxes Are Making Doctors’ Jobs Harder<br></h1><p id="artcont">Without the support of social platforms, our efforts to stamp out viral misinformation feel futile. By Seema Yasmin and Craig Spencer Dr. Yasmin is the author of “Viral B.S.: Medical Myths and Why We Fall for Them.” Dr. Spencer is an emergency medicine physician. The news came from a colleague — not a doctor but someone who works in the emergency room and has seen firsthand the devastation caused by the pandemic. “There is a cure for Covid-19,” he said. “It must be true because a doctor friend shared a Facebook post about this cure.” When confronted with the latest, credible scientific evidence — that there is no cure for Covid-19, that the disease has killed more than 180,000 Americans precisely because we have no effective way of averting death for the millions who are infected — he doubled down. “But I saw it on Facebook,” he said. In the emergency room and in conversations with the American public through cable news interviews and Op-Eds like this one, we’ve both been working to dissect and debunk the many myths about this new virus, its potential treatments and the possibility of a vaccine. We read the mistruths on our patient’s phones, listen to theories borrowed from internet chat rooms and watch as friends and family scroll through Facebook saying, “Here — it says that this was definitely created in a Chinese laboratory.” Seven months into the worst pandemic of our lifetime, the virus continues to spread alongside medical myths and health hoaxes. False news is not a new phenomenon, but it has been amplified by social media. A new report about Facebook from Avaaz, a nonprofit advocacy organization that tracks false information, shows how widespread and pervasive this amplification is. Websites spreading health hoaxes on Facebook peaked at an estimated 460 million views on the platform in April 2020, according to the report, just as the virus was spreading around the world and overwhelming hospitals in New York City. Facebook claims to assess and add warning labels to factually incorrect posts; but in a subset of posts analyzed by Avaaz, only 16 percent of those containing health misinformation had a warning label. Facebook’s algorithm rewards and encourages engagement with content that provokes strong emotions, which is exactly the kind of content we warn patients to doubt and carefully assess, since false information is often packaged as novel and sensational. The report’s title calls Facebook’s algorithm “A Major Threat to Public Health” — something our clinical and research experiences amply confirm. 