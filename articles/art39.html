<html><head><link rel="stylesheet" type="text/css" href="css.css"></head><h1 id="artitle">Tracking Viral Misinformation Ahead of the 2020 Election<br></h1><p id="artcont">By Kellen Browning Twitter stepped up its actions against misleading tweets ahead of Election Day. So how are the moves working out? A tweet by President Trump late on Monday provides a case study. In his tweet, Mr. Trump claimed without evidence that the Supreme Court’s recent decision to allow Pennsylvania absentee ballots to be received up to three days after Nov. 3 would “allow rampant and unchecked cheating” and “induce violence in the streets.” Thirty-six minutes after the tweet was posted, Twitter labeled it as containing disputed or misleading content about the election. It was the second time Twitter had used that label on one of Mr. Trump’s tweets since updating its policies to clamp down on election misinformation on Oct. 9. It had also used the label on Oct. 26 when Mr. Trump tweeted without evidence that there were “big problems and discrepancies” with mail-in ballots. Twitter’s act of labeling Mr. Trump’s tweet on Monday also meant that people could not easily share the post, unless they posted their own message with his tweet quoted underneath. That quickly slowed the tweet’s overall spread, according to an analysis by the Election Integrity Partnership, a coalition of misinformation researchers. Before Mr. Trump’s tweet was labeled, it was shared or replied to about 827 times a minute. After it was labeled, that dropped to 151 times a minute, according to the E.I.P. analysis. 3/5 Around 40 min later, Twitter took action by hiding the tweet behind an informational label and preventing it from being retweeted. The graph below shows the rate of retweets and quote tweets, which were dramatically reduced after Twitter took action https://t.co/t0w183GgxZ pic.twitter.com/ZN5CwHvTxn Even so, Mr. Trump’s post had already been retweeted more than 55,000 times and liked more than 126,000 times, according to the E.I.P., which said “much of the damage was likely already done.” Lisa Kaplan, the founder of Alethea Group, a company that helps public officials and private clients fight misinformation, said the data suggested that Twitter’s tools for fighting misinformation could be effective, especially if applied faster. “Those decisions need to be made a lot more quickly; they should be split-second decisions,” she said. Still, she cautioned that the tweet could have been shared beyond Twitter’s service if it was posted to other social media platforms. A Twitter spokeswoman said it placed the label on Mr. Trump’s tweet so it was “in line with our civic integrity policy.” Facebook also added a label to Mr. Trump’s identical post on the social network on Monday. Facebook’s label said that voter fraud was rare, but Mr. Trump’s post was still shareable and had more than 78,000 likes, 5,000 shares and 18,000 comments as of Tuesday morning. A Facebook spokesman said the label was part of the company’s efforts to counter election-related misinformation. By Davey Alba “Hello, this is just a test call,” a female robocall voice intones. “Time to stay home. Stay safe and stay home.” The calls began back in June, according to YouMail, a service that offers robocall blocking for smartphones. But they have increased greatly as the election has approached, grabbing the attention of some election officials in recent days. YouMail found evidence that the robocalls have reached 280 of the country’s 317 area codes since this summer, peaking at more than 600,000 calls in one day. Over all, the company has tracked 10 million similar calls in October. Though the calls do not mention the election explicitly, their timing and lack of information were suspicious, said Alex Quilci, YouMail’s chief executive. Robocalls in favor of a political candidate typically include some “get out the vote” information or a call for donations, he said. These did not. “It’s worthy of investigation to try to figure out what’s going on here,” Mr. Quilci said. “To do something at this scale is a bit of work.” Mr. Quilci added: “What scares me is that this shows that someone" — a foreign or domestic bad actor — “could cause havoc with robocalls.” The Washington Post earlier reported news of the robocall campaign. Election experts focused on disinformation tend to focus on the spread of false information on social media platforms like Facebook and Twitter. But misinformation can reach voters through a variety of mediums, including text messages and robocalling. Such methods can help misinformation stay under the radar, allowing it to spread widely before it is noticed. On Tuesday morning, Michigan Attorney General Dana Nessel warned constituents that “multiple robocalls” had gone out to Flint, Mich., residents directing them to vote on Wednesday. “Obviously this is FALSE and an effort to suppress the vote,” Ms. Nessel said in a tweet. “No long lines and today is the last day to vote.” Getting reports of multiple robocalls going to Flint residents that, due to long lines, they should vote tomorrow.
Obviously this is FALSE and an effort to suppress the vote. No long lines and today is the last day to vote. Don’t believe the lies! Have your voice heard! RT PLS. The New York state attorney general, Letitia James, announced on Tuesday that she was investigating the robocalls. “Attempts to hinder voters from exercising their right to cast their ballots are disheartening, disturbing, and wrong,” Ms. James said in a statement. “What’s more is that it is illegal, and it will not be tolerated.” By Kevin Roose It’s still early on Election Day, but the internet’s misinformation peddlers are already hard at work. As millions of voters head to the polls, social media posts with false or misleading claims began to emerge early Tuesday morning from battleground states, including Pennsylvania and Michigan. Many of these claims followed the familiar misinformation narratives we’ve come to expect on Election Day: viral videos of broken voting machines, allegations of fishy polling place behavior and fake or exaggerated claims of attempted voter suppression. In Philadelphia, election officials debunked a misleading claim from a Twitter user who posted a photo of a sign promoting Democrats at a polling station. The original, misleading tweet, which came from a reporter at the right-wing website Newsmax, was shared more than 7,000 times. Members of our Election Task Force have investigated this allegation. This polling place is located in an interior room and the sign in question is further than 10 feet from it. This tweet is deliberately deceptive. #PhillyVotes #Election2020 https://t.co/szKgxoigVm Several viral tweets have also spread unconfirmed rumors of excessively long lines at polling places in Republican districts, broken voting machines in Republican-leaning precincts or other attempts to suppress votes for President Trump. Many of these posts were hashtagged #StopTheSteal. Not all misinformation was sent online. In Michigan, the state’s attorney general, Dana Nessel, wrote on Twitter that she had received reports of robocalls made to Flint residents with inaccurate information about when they should vote. Getting reports of multiple robocalls going to Flint residents that, due to long lines, they should vote tomorrow.
Obviously this is FALSE and an effort to suppress the vote. No long lines and today is the last day to vote. Don’t believe the lies! Have your voice heard! RT PLS. By Sheera Frenkel Rigged voting machines. Tossed ballots. Intimidating federal agents. In a year awash in misinformation, it should be no surprise that false reports about the 2020 election are circulating through social media, text messages and emails. Some of that misinformation — rumors, misleading videos and mislabeled photographs — has been making the rounds for weeks as millions of Americans voted early. The New York Times has been debunking that information daily. On Tuesday, experts who study misinformation and social media companies expect certain rumors to return. Here are the some of the more common false claims that voters might see. Claim: The billionaire George Soros owns Smartmatic, a company that makes voting machines. He can manipulate the machines toward a candidate of his choosing. Fact: Mr. Soros does not own Smartmatic. Background: Rumors that Mr. Soros, a well-known donor to liberal causes, owns Smartmatic have circulated for years, including during the 2016 presidential election and the 2018 midterm elections. Mr. Soros’s only connection to Smartmatic is through the company’s chairman, Mark Malloch-Brown, who serves on the board of Mr. Soros’s Open Society Foundation. “George Soros does not have and has never had any ownership stake in Smartmatic,” according to the Smartmatic website. Claim: There are photographs of ballots being thrown away, providing proof of problems with mail-in voting in California. Fact: The photographs depict old, empty envelopes from the November 2018 midterm elections that were discarded after the vote was counted. Background: The images have been circulating in recent months to back claims made by President Trump that mail-in voting, which is expected to nearly double because of the pandemic, will increase voter fraud. Republicans in Congress as well as right-wing outlets have shared the photographs. On Sept. 25, The Gateway Pundit posted an article that presented the photographs as evidence that ballots were being thrown into dumpsters. The same day, the photographs were featured in a tweet by Elijah Schaffer, a reporter for the right-wing Blaze TV. The tweet was shared over 5,000 times and liked over 7,000 times before Twitter removed it. California’s Sonoma County, where the photographs were taken, has clarified multiple times that the pictures “are of old empty envelopes from the November 2018 election that were disposed of as allowed by law.” In a variation of this claim, photographs of printing waste from a direct mail company being shredded have falsely implied that mail-in ballots were being destroyed. Claim: People are casting multiple votes using mail-in ballots or absentee ballots. Fact: Election experts have calculated that, in a 20-year period, fraud involving mailed ballots has affected 0.00006 percent of votes, or one case per state every six or seven years. Background: Several viral Twitter posts have claimed that mail-in ballots cannot be “verified” or have already been cast. Mr. Trump, who has repeatedly attacked state efforts to expand voting by mail, has falsely said mail-in ballots are “dangerous,” “unconstitutional,” “a scam” or rife with “fraud.” According to the National Conference of State Legislatures, mail-in ballots are the “gold standard of election security.” In most states, registered voters need to apply to vote through an absentee or mail-in ballot. In nine states and Washington, D.C., registered voters are automatically sent ballots by mail. In all states, elections officials have put systems in place to ensure that each voter is able to vote only once and cannot return multiple ballots or place multiple ballots in the same envelope. Voters who cast their ballots by mail receive a ballot packet (the envelope addressed to the voter, the ballot, the return envelope, a security envelope and any instructions) with a unique identification that is tied to the individual voter. If a voter requests a replacement ballot because of a damaged one, the first unique identification remains on file but is voided so that ballot envelope cannot be returned. The new ballot is sent with a new unique identification. Many states also require the signature on the returned ballot be compared with a signature on file. States also ensure that voters casting their ballots are still eligible to vote. In August, some of Mr. Trump’s supporters circulated claims that “846 dead people” tried to vote in Michigan’s primary. That story was not true. A news release by Michigan’s secretary of state said 846 voters had died “after casting their absentee ballot but before Election Day.” Those votes were not counted, in accordance with local laws in Michigan. Claim: People can vote by text message, by email or on a state-run website. Fact: Outside of a small amount of overseas absentee voters and military personnel, no state allows Americans to vote by email, website or text message. Background: In 2016 and 2018, posts on Facebook, Twitter and other social media sites claimed that voters could cast their ballots through newly formed websites, or through text-messaging services. Facebook, Twitter, and Google remove posts that mislead voters about how, when or where they can vote. However, there are concerns that this year some of those claims have circulated through encrypted messaging apps, which cannot be easily monitored. Claim: Voting machines are malfunctioning and causing votes to be improperly recorded. Fact: A handful of voting-machine malfunctions are reported every election cycle in most states. The errors are most often due to mistakes by users. Background: Frequently circulated videos purport to show machines malfunctioning or refusing to let people cast their vote for a particular candidate. A 2016 video shot by a woman in Pennsylvania and posted to Twitter claimed that a voting machine was not allowing her to vote for Mr. Trump. The video, which is likely to resurface this year, was provided as evidence that machines were rigged. But as ProPublica reported, the problem with the machine was user error. Election officials have said there may be accurate reports of troubles with voting machines. Those problems can be made worse by bad weather, like heat waves or high humidity, or power outages. This year, because of the pandemic, officials expect that many people will use hand sanitizer before handling their ballots or touching voting machines. The hand sanitizer is likely to build up during the day and could cause more machines to malfunction. Malfunctioning machines would be removed. Voters can ensure their votes are correctly cast by requesting a paper record after they have voted. Five states tdo not provide a paper trail of votes: Louisiana, Georgia, South Carolina, New Jersey and Delaware. In those states, voters are encouraged to double-check their choices before submitting their vote, and should notify poll workers if a machine is malfunctioning. Claim: U.S. Immigration and Customs Enforcement agents will be at polling stations. Fact: ICE will not be at polling stations. Background: This rumor has made the rounds for a decade. During the 2018 election, claims that ICE would be at polling stations proliferated on Twitter, making misinformation aimed at suppressing the vote one of the most prevalent forms of misinformation on the platform, according to Twitter. The rumor has returned this year, including in one Facebook post that has been shared nearly 4,000 times, despite a “false information” label from Facebook. ICE has repeatedly denied that it will have agents at polling stations and recently issued another denial. “Rumors that ICE plans to engage in patrols or enforcement operations at polling locations are false,” said an agency spokesman, Mike Alvarez. “Any fliers or advertisements claiming otherwise are incorrect and not sanctioned by ICE.” By Sheera Frenkel A video of Joseph R. Biden Jr. deceptively edited to make it appear as though he were admitting to voter fraud was viewed more than 17 million times on social media platforms, according to Avaaz, a progressive human-rights nonprofit that studied the video. The video was an edited clip from an Oct. 24 appearance by Mr. Biden, the Democratic presidential nominee, on the podcast “Pod Save America.” When asked about efforts to bolster election security, Mr. Biden gave a long answer and discussed Obama administration efforts to protect against voter fraud. He added that he had put together “the most extensive and inclusive voter fraud organization in the history of American politics.” The deceptively edited video featuring that part of his statement — taken out of context to make it appear that Mr. Biden supported voter fraud — was shared on dozens of right-wing YouTube channels, Twitter accounts and Facebook pages. It was not clear on Monday who had made the edited video. A spokesman for Mr. Biden’s campaign clarified that he, as seen in the full video, was discussing his efforts to prevent voter fraud. “We have assembled the most robust and sophisticated team in presidential campaign history to confront voter suppression and fight voter fraud however it may present itself,” said TJ Ducklo, the campaign’s national press secretary. Social media companies had a haphazard response to the video. Facebook, where the video had received hundreds of thousands of views, added a label to some versions of the video warning viewers that it lacked context and contained misleading information. But other versions did not receive a label, and on Monday evening it was unclear why. A post about the video that had more than 110,000 views on the Facebook page of President Trump’s son Eric was labeled. But a post on the Team Trump Facebook page, which was viewed more than 264,000 times, was not. Facebook did not respond to a request for comment. Several versions of the video shared on YouTube by President Trump and right-wing figures were viewed more than 800,000 times. There was no label on any of those videos, and Ivy Choi, a YouTube spokeswoman, said the videos did not violate YouTube’s Community Guidelines. YouTube also has a “fact check information panel” above its search results. When people searched for videos on YouTube with terms like “Joe Biden voter fraud,” the company featured the original, unedited video ahead of the many edited versions, Ms. Choi said. On Twitter, where several high-profile accounts shared the video, it had more than 8.4 million views and had been shared thousands of times by Monday evening. The company was reviewing the video, a Twitter spokesman said. The video was one of several shared by right-wing accounts over the weekend that tried to discredit the Biden campaign. Another video was altered to make it appear as though Mr. Biden were addressing the wrong state during a campaign stop. In the video, he was addressing a crowd in St. Paul, Minn., when he said, “Hello, Minnesota!” In an edited version of the video, banners behind Mr. Biden were altered to read “Tampa, Florida.” That video had been viewed over one million times on Twitter, according to a report on CNN. By Davey Alba Which states have seen the highest volume of viral misinformation about voting by mail this election season? Those that are most in play between President Trump and Joseph R. Biden Jr., according to new data. People in several battleground states, which are likely to decide the presidential race, saw the most distortions and falsehoods about voting by mail between Sept. 1 and Oct. 29, according to Zignal Labs, a media insights company that tallied the likely misinformation mentions across online news outlets, cable television, print and social media. Many of the lies originated after mail-in ballots were sent incorrectly in those states, Zignal found, which then led to false claims that the ballots had been tampered with and questions about the reliability of the vote. Of the 1.1 million total voting-by-mail falsehoods that Zignal tallied, Pennsylvania topped the list with 227,907 of them — or more than double the next state on the list. Many of the misinformation mentions in Pennsylvania started after a federal prosecutor there said on Sept. 24 that a small number of military ballots had been “discarded” in Luzerne County, including ballots cast for Mr. Trump. The county later said the ballots, which were found in a trash bin, had been incorrectly thrown away by a contractor, who was let go after the incident. But the announcement was then twisted — including by Mr. Trump — as evidence of voter fraud in the state. Pennsylvania, which Mr. Trump won by less than one percentage point in 2016, has been a heavy focus of the Republican and Democratic presidential campaigns. The state has 20 Electoral College votes to give, the most of any battleground state except for Florida, which has 29. Of the other states that saw high volumes of voting-by-mail misinformation, Ohio was second with 89,996 such mentions, Zignal found. Third was Texas, with 68,005 mentions, Zignal said. Ohio and Texas are also considered swing states. Other states that are not considered swing states also saw lies about voting by mail, though to a lesser degree. New York had 38,557 such mentions and California, where state Republicans were ordered to remove private ballot collection containers marked as “official” drop boxes, saw 29,030 misinformation mentions, Zignal said. For the other states, see the full tally here. Lisa Kaplan, the founder of Alethea Group, a company that helps fight election-related misinformation, said the flood of falsehoods was undermining faith in democracy. “Voter fraud is incredibly rare,” Ms. Kaplan said. “But nefarious actors are distorting reality.” She added that the ultimate effect was “that the electorate is the collateral damage.” By Kellen Browning Instagram on Thursday took aim at the spread of misinformation on its platform, announcing that it would temporarily eliminate users’ ability to view some recent posts ahead of Election Day. In two tweets, Instagram said it would remove the “recent” tab from hashtag pages. Previously, users could view the most recent posts tagged with a particular hashtag. Now, only “top” posts under a specific hashtag that have been reviewed by the platform will be viewable. Instagram, which is owned by Facebook, said the change was made to “reduce the real-time spread of potentially harmful content that could pop up around the election.” As we near the U.S. elections, we’re making changes to make it harder for people to come across possible misinformation on Instagram. The change took effect Thursday night and the “recent” tab will return sometime after the election, an Instagram spokeswoman said. The platform said it hopes the change will allow it to proactively stop misinformation from spreading, rather than having to wait until a falsehood has already been widely shared. Nina Jankowicz, a disinformation analyst at the Wilson Center, a nonpartisan think thank, said Instagram’s decision, just days before the election, was “rather late” but “better than nothing.” “I hope in the future the social media platforms recognize that elections are an inflection point in disinformation campaigns, not an end point,” she said. “A decision like this earlier in the cycle might have lessened the spread of voting misinformation, for instance.” Ms. Jankowicz said much of the misinformation spreading on Instagram was related to QAnon, the baseless pro-Trump conspiracy theory, and false information about Senator Kamala Harris of California, the Democratic vice-presidential nominee. Instagram’s decision follows crackdowns on viral falsehoods by Facebook and Twitter. Twitter recently added context to trending topics and de-emphasized retweets ahead of the election, while Facebook said it would ban political ads indefinitely. Both companies have added some labels to misleading posts and highlighted accurate voting information after rising alarm about the possibility of a disputed election outcome and the chaos that could follow. By Davey Alba, Kellen Browning and Jacob Silver Falsehoods about Tuesday’s election have overwhelmed local election officials, who said they were dealing with “tsunamis of misinformation,” have lost sleep and were working extra long hours. The officials told us they were dealing with several common flavors of election-related misinformation. So we decided to track three categories of the rumors they had encountered using CrowdTangle, a Facebook-owned analytics tool, and then focused on the spread of one the lies in each of the categories. We also recorded the volume of tweets about the rumors we followed using BuzzSumo, another analytics tool. The data showed how a single rumor pushing a false narrative could rapidly gain traction on Facebook and Twitter, generating tens of thousands of shares and comments. That has made the misinformation particularly hard for elections officials to fight. “The true costs of misinformation are not paid by platform companies,” said Joan Donovan, the research director at Harvard University’s Shorenstein Center. “They are paid by everyone else who has to deal with the aftermath.” A spokesman for Facebook, Andy Stone, said that it prohibits voter interference, is working with fact-checking organizations and has introduced a voter information hub of accurate information. Twitter said it did not create any specific Twitter Moments explaining these particular rumors, but does aim to proactively debunk false claims and provide information about voting by mail. Here’s what we found. This misinformation features the unproven assertion that ballots are being “harvested,” or collected and dropped off in bulk by unauthorized people. In the example we focused on, Representative Ilhan Omar, a Minnesota Democrat, was falsely accused last month of being engaged in or connected to systematic illegal ballot harvesting. There were 3,959 public Facebook posts sharing this rumor, according to our analysis. Those posts generated 953,032 likes, comments and shares. Among those who shared the lie were two pro-Trump Facebook groups targeting Minnesota residents, as well as President Trump himself. At least 26,300 tweets also discussed the falsehood. Jeremy Slevin, a spokesman for Ms. Omar, said in an emailed statement that there was no truth to the claim. Mail-in ballots and related materials being tossed was another popular falsehood that election officials said they were hearing. We looked at one of these rumors, which was pushed by a far-right website called The Right Scoop. This month, the site published an article with the headline, “Tons of Trump mail-in ballot applications SHREDDED in back of tractor trailer headed for Pennsylvania.” The article generated 163 individual public posts on Facebook. It was liked, commented and shared 91,000 times on the social network, according to our analysis. It was also shared 1,032 times on Twitter. Politifact debunked the video on which the article was based. Facebook added a label to posts that shared the rumor saying it contained false information. The Right Scoop later corrected its post — but its correction did not travel as far as the lie, receiving just a single like on Facebook. The Right Scoop did not respond to a request for comment. Election officials also said people were confronting them with false assertions that antifa, the loose collection of left-wing activists, and Black Lives Matter protesters were coordinating riots at polling places across the country. One of those rumors began this month when The Federalist, a conservative outlet, noticed that a liberal activist website called Shut Down DC said people should protest on the streets if Mr. Trump was re-elected. Right-wing commentators then attached inflammatory captions to their posts sharing The Federalist’s article. Many said it was evidence of planned far-left violence on Election Day and after, and stated, without proof, that Black Lives Matter was involved. The false rumor was then shared in 472 public Facebook posts, according to our analysis. It generated 99,336 likes, shares and comments. On Twitter, the rumor was shared at least 400 times. Craig Sawyer, a right-wing commentator and Marine veteran, shared the rumor on Facebook on Oct. 16. He said in an email that his post was not a call for violence and that The New York Times should focus on “the key planners and financiers of all the rioting, arson, looting and murder” instead. By Cade Metz Be aware: Fake Twitter accounts will very likely sow disinformation in the few remaining days before Election Day on Nov. 3. This week, researchers at the University of Southern California released a new study that identified thousands of automated accounts, or “bots,” on Twitter posting information related to President Trump, Joseph R. Biden Jr. and their campaigns. The study examined over 240 million election-related tweets from June through September. Many of these bots, the study said, spread falsehoods related to the coronavirus and far-right conspiracy theories such QAnon and “pizzagate.” The study said that bots accounted for 20 percent of all tweets involving these political conspiracy theories. “These bots are an integral part of the discussion” on social media, said Emilio Ferrara, the University of Southern California professor who led the study. A Twitter spokesman questioned the study’s methods. “Research that uses only publicly available data is deeply flawed by design and often makes egregiously reductive claims based on these limited signals,” the spokesman said. “We continue to confront a changing threat landscape.” Social media companies such as Twitter and Facebook have long worked to remove this kind of activity, which has been used by groups trying to foment discord in past elections in the United States and abroad. And the University of Southern California study showed that about two-thirds of the conspiracy-spreading bots it identified were no longer active by the middle of September. In some cases, bots exhibit suspicious behavior. They might “follow” an unusually large number of other accounts — a number nearly as large as the number of accounts following them — or their usernames will include random digits. But identifying bots with the naked eye is far from an exact science. And researchers say that automated accounts have grown more sophisticated in recent months. Typically, they say, bots are driven by a mix of automated software and human operators, who work to orchestrate and vary the behavior of the fake accounts to avoid detection. Some bots show signs of automation — like only retweeting rather than tweeting new material, or posting very frequently — but it can be difficult to definitively prove that accounts are inauthentic, researchers say. An automated account may stop tweeting at night, for example, as if there is a person behind it who is sleeping. “You can clearly see they are automated,” said Pik-Mai Hui, an Indiana University researcher who has helped build a new set of tools that aim to track these bots in real time. “But they are operated in a way that makes it very difficult to say with complete certainty.” These bots are operating on both sides of the political spectrum, according to the study from the University of Southern California. But right-leaning bots outnumbered their left-leaning counterparts by a ratio of 4-to-1 in the study, and the right-leaning bots were more than 12 times more likely to spread false conspiracy theories. The study indicates that 13 percent of all accounts tweeting about conspiracy theories are automated, and because they tweet at a higher rate, they are sending a much larger proportion of the overall material. “This is the most concerning part,” Dr. Ferrara said. “They are increasing the effect of the echo chamber.” By Cade Metz Last week, a political action committee called the American Principles Project unveiled a new video on Twitter falsely claiming that Democratic presidential nominee Joseph R. Biden Jr. supported sex changes for 8-year-olds. Since Friday, a similar video has also appeared on Facebook as many as 100,000 times — primarily in Michigan, a swing state in the Nov. 3 election. What has been harder to pinpoint is how widely the video has been spreading through text messages. Though companies like Facebook and Twitter have developed tools for tracking and policing disinformation on their social networks, texting activity is largely a free-for-all that receives little scrutiny from tech companies and government regulators. “There is no way to audit this,” said Jacob Gursky, a research associate at the University of Texas at Austin. “Organizations are just collecting cellphone numbers from data brokers and mass-texting people.” The video circulated in Michigan, Wisconsin and Pennsylvania as part of a coordinated texting campaign, according to a study by researchers at the University of Texas at Austin. Over the weekend, it reached a reporter who covers online disinformation for the news site Protocol. The reporter had a Pennsylvania cellphone number. Twisting the meaning of Mr. Biden’s statements during a recent “town hall” event — which condemned discrimination against children who identify as transgender but did not address sex changes — the campaign was a high-profile example of increasingly widespread efforts to distribute disinformation through text messages. “During a recent town hall, Joe Biden endorsed giving 8- to 10-year-olds sex change treatments,” the texts read. “This is way too extreme for me. I can’t support him.” The texts tracked by Mr. Gursky and his fellow researchers said they were sent by the American Principles Project, but they referred to the organization only as “the APP PAC.” The texts purport to arrive from a “Democratic volunteer.” The American Principles Project did not respond to a request for comment. Data on texting campaigns is hard to come by. But Robokiller, a company that blocks automated phone calls and texts, said Americans received 2.6 billion political text messages in September, a 400 percent increase since June. The company estimated that since June, Republication-affiliated organizations have sent roughly six times more messages than their Democratic counterparts. The Texas researchers said texting campaigns are in part a reaction to increased scrutiny on social media services. As Facebook and Twitter have pushed disinformation networks off their services, the networks have resurfaced on private texting apps like Signal, Telegram and WhatsApp, where they can continue operate without being monitored. Private disinformation networks are prevalent in places like India and Mexico, the researchers said. But they are becoming more common in certain parts of the United States, such as southern Florida, where apps like WhatsApp are popular. By Sheera Frenkel Facebook said on Tuesday that it had removed ads from both the Trump and Biden presidential campaigns that arguably could mislead voters in states where early voting has not started. The ads were bought by the campaigns over the weekend, as part of a last-minute push to secure Facebook ads before the end of Monday. Facebook recently said it would not accept any new political ads in the week before Election Day, but would continue to run ads that had been bought ahead of time. The Trump and Biden campaigns did not immediately respond to requests for comment. Megan Clasen, a Biden campaign media adviser, tweeted that Facebook had told her office that it could not run ads that urged people to vote by saying that “Election Day is tomorrow” or “Election Day is today.” She then pointed to a similar ad by the Trump campaign that said, “Election Day is today.” Facebook told the Biden campaign we could not launch ads that say “Election Day is tomorrow” or “Election Day is today” pic.twitter.com/w9W7F1915g Several hours after journalists and Biden campaign officials contacted Facebook, the Trump campaign ad was removed. Facebook said the ads were misleading because they could be seen by voters in states where voting was not currently open. “As we made clear in our public communications and directly to campaigns, we prohibit ads that say ‘Vote Today’ without additional context or clarity,” a Facebook spokesman said. Facebook had previously said it would not fact-check political ads. But the company said it would remove advertisements that could mislead voters or provide incorrect information on how to vote. By Kevin Roose This has been, by any measure, a bad year for consensus reality. First, there was President Trump’s impeachment — a divisive and emotionally charged proceeding that unleashed a torrent of lies, exaggerations and viral innuendo. Then came the Covid-19 pandemic — an even bigger opportunity for cranks, conspiracy theorists and wishful thinkers to divide us along epistemic lines, into those who believed the experts and those who preferred to “do their own research.” The Black Lives Matter protests this summer were a feeding frenzy for those looking to distort and reframe the narrative about police violence and racial justice. And while election years are always busy times for fact-checkers, Mr. Trump’s fusillade of falsehoods about voter fraud, Spygate and Hunter Biden’s emails this year has resulted in a bigger challenge for those charged with separating truth from fiction. Zignal Labs, a firm that tracks online misinformation, analyzed which major news topics in 2020 were most likely to generate misinformation. Its data, which draws from sources including social media apps like Facebook, Twitter, Instagram and Reddit, as well as newspapers and broadcast TV transcripts, isn’t an exact accounting of every single piece of misinformation out there. But it’s a rough gauge of which topics are most frequently used as vehicles for misinformation, by those looking to inject confusion and chaos into media narratives. (Quick methodological note: These “misinformation mentions” are limited to topics related to either the election or the Covid-19 pandemic, and are calculated by Zignal’s automated system based on the number of mentions of a given term along with a term that is frequently associated with misinformation. So, for example, a post that mentions vaccines in the context of Covid-19 would not be counted as a misinformation mention, but a post that mentions vaccines along with a hashtag like #FauciTheFraud or a name like Bill Gates — a frequent target of anti-vaccine activists — would be counted, even if the underlying story was debunking such a false claim.) The topic most likely to generate misinformation this year, according to Zignal, was an old standby: George Soros, the liberal financier who has featured prominently in right-wing conspiracy theories for years. Out of 2.6 million total media mentions of Mr. Soros so far this year, nearly half (1.1 million) were accompanied by terms (“Soros-funded,” “bankroll”) that suggested that he played a role in funding left-wing agitators. They peaked this summer, as false claims that Mr. Soros had funded Black Lives Matter protests went viral following the killing of George Floyd. Second on the list was Ukraine, which peaked as a misinformation topic in January and February, during Mr. Trump’s impeachment proceedings along with keywords like “deep state” and “WWG1WGA,” a shorthand used by followers of the QAnon conspiracy movement. About 34 percent of Ukraine’s 9.2 million total media mentions were flagged as misinformation-related. Third was vote-by-mail, which has been the subject of a torrent of misinformation by Mr. Trump and right-wing media outlets. Roughly one out of every five vote-by-mail stories in 2020 has been misinformation, according to Zignal’s analysis, with terms like “fraud” and “scam” being common red flags. With all three subjects, some of the most common spreaders of misinformation were right-wing news sites like Breitbart and The Gateway Pundit. YouTube also served as a major source of misinformation about these topics, according to Zignal. Of course, the misinformation we’ve seen so far this year might pale in comparison to what happens after next week’s election, if a contested result or allegations of fraud result in a new wave of false or misleading claims. Social media platforms have signaled that they will remove premature claims of victory, and attempts to delegitimize the election. But they also pledged to take down misinformation about Covid-19, and have had only mixed success in doing so. Here are the topics that generated the highest percentage of misinformation narratives: 1. George Soros (45.7 percent misinformation mentions) 2. Ukraine (34.2 percent) 3. Vote by Mail (21.8 percent) 4. Bio Weapon (24.2 percent) 5. Antifa (19.4 percent) 6. Biden and Defund the Police (14.2 percent) 7. Hydroxychloroquine (9.2 percent) 8. Vaccine (8.2 percent) 9. Anthony Fauci (3.2 percent) 10. Masks (0.8 percent) By Daisuke Wakabayashi With a week to go before Election Day on Nov. 3, YouTube, like other social media firms, is girding for a test of its ability to keep misinformation and other problematic videos off its site. In a blog post on Tuesday laying out its approach, the company said it planned to apply its basic approach of removing content that violates its policies, elevating videos from authoritative sources, and limiting the spread of so-called borderline that tests the boundaries of its policies. YouTube said it would be especially vigilant about content that encourages interference in the electoral process, such as videos inciting others to commit violent acts at polling stations or ones making false claims that mail-in ballots have been manipulated. “Our teams have been working around the clock to make sure we have the systems and policies to prevent the abuse of our systems and provide access to authoritative information this election season,” wrote Leslie Miller, YouTube’s vice president for government affairs and public policy. The election is a critical test of YouTube’s efforts to prevent the spread of dangerous conspiracy theories and hate speech on its platform. As the biggest repository of videos on the internet, YouTube has come under criticism in recent years for not doing enough to rein in the toxic content on its site while pushing viewers toward increasingly radical points of view. In the days leading up to Nov. 3, YouTube’s home page will feature links to information about how and where to vote. As the polls close, YouTube will feature a playlist of live election results coverage from what it deems authoritative news sources. YouTube did not provide a full list of the sources, but cited CNN and Fox News as authoritative sources. Starting on the day of the election, YouTube said, it will place a so-called information panel above election-related search results and below videos discussing the election. The panel will warn viewers that results may not be final and offer a link to Google’s real-time election results feature, based on information from The Associated Press. By Nick Corasaniti Local election officials, politicians and disinformation researchers continue to express concern about how misinformation about voting could disrupt Election Day next week. False and misleading information, research shows, has already been spreading widely. The 2019 race for governor of Kentucky illustrates what can go wrong, as we explored in the latest episode of “Stressed Election.” In that race, the standing governor, Matt Bevin, a Republican, disputed the results when the vote tally showed him narrowly losing to his Democratic challenger, Andy Beshear. Mr. Bevin and some of his allies argued, without showing any evidence, that there were voting irregularities and fraud, echoing some false and misleading statements made on social media. The governor initially refused to concede even though returns showed him trailing by about 5,000 votes. Mr. Bevin conceded about a week later. The race offers some lessons about the power of disinformation in American elections: 1. Misinformation efforts don’t need to be sophisticated to be successful. In Kentucky, an account with just 19 followers sent out a tweet on election night that claimed to have “shredded a box of Republican ballots.” The tweet, sent as a joke by a college student, would eventually reach thousands. 2. Stopping the spread of misleading election information is not easy. Election officials noticed the false “shredded” tweet, which was retweeted by a few popular conservative accounts, and reported it to Twitter. The company removed the post within an hour, but screenshots of the post were retweeted by dozens of accounts, with retweets reaching well into the thousands. Tracking all of those screenshots proved difficult for both election officials and Twitter. 3. One piece of misinformation can beget much more. The sudden spread of the false tweet about shredding ballots seemed to be a green light for other claims. Some tweets started to question the accuracy of voter rolls in Kentucky, others wondered about “hackers” attacking the “cloud” where election results were stored, except there is no “cloud” used in Kentucky elections. And baseless claims of voter fraud were rampant. 4. There are networks ready to amplify and spread misinformation. Some groups on Twitter spread countless conspiracies, be it the QAnon cabal conspiracy or an anti-mask conspiracy. These networks can quickly seize on a piece of conspiratorial misinformation and amplify and accelerate its spread, which is part of why a single tweet from an obscure account reached so many in Kentucky. 5. An extremely close election is particularly ripe for misinformation. Following election night in Kentucky, the brush fire of misinformation that was spreading online quickly took hold offline. Mr. Bevin’s supporters staged news conferences with baseless claims of fraud, and set up a robocall network telling people to “please report suspected voter fraud” to the state elections board. Online, the discussion had now moved far beyond a case of shredded ballots to accusations of a stolen or rigged election. By Mike Isaac Twitter’s emphasis on up-to-the-second posts has made the site a must-visit destination for people to find the latest in news and current events. It has also made Twitter a vessel for the spread of false information. To stem that tide, Twitter on Monday announced a new effort to preemptively debunk, or “prebunk” in Twitter parlance, some of the most commonly circulated false and misleading information about the election. The company will, for the first time, pin information to the top of users’ timelines about how to vote, as well as a notice that voting results may not come immediately on Election Day — two common topics for misinformation across social media. “We believe it’s critical that we make it easy for people to find that information,” said Nick Pacilio, a Twitter spokesman. “These prompts will alert people that they may encounter misinformation, and provide them with credible, factual information on the subject.” The move is the latest in a series of actions taken by Twitter, Facebook and YouTube to place safeguards on their networks in the days leading up to Election Day. Lawmakers and the public harshly criticized the companies for allowing misinformation to spread ahead of the 2016 presidential election. Facebook, which at three billion users is much larger than Twitter, has announced several changes in the past few months to stem misinformation about the election. It has started to pin facts about voting to the top of users’ timelines, added labels to posts that spread false voting information, placed a ban on new political advertising in the seven days before Election Day, and removed paid political ads entirely after the polls close. Twitter has taken several steps, too. Last week, the company turned off some of the features that help tweets go viral faster. That includes adding an extra step to retweeting posts, and prompting users to avoid retweeting a post with a link to a news article if they had not already read the attached article. The new pinned information will appear in the home timeline of every person with a Twitter account located within the United States, and will be available in 42 languages, beginning Monday. </p><a href="http://manej.life/" id="footer">Go back to MANEJ</a>